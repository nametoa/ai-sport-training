#!/usr/bin/env python3
"""COROS Training Dashboard â€“ Streamlit app."""
from __future__ import annotations

import json
import math
import os
import re
import sys
from datetime import datetime, timedelta, date
from pathlib import Path

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Paths & constants
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_DIR = Path(__file__).parent / "data"
PLANS_DIR = Path(__file__).parent / "training_plans"

SPORT_TYPE_MAP = {
    100: ("ğŸƒ", "è·‘æ­¥"),
    102: ("ğŸ”ï¸", "è¶Šé‡è·‘"),
    200: ("ğŸš´", "éª‘è¡Œ"),
    402: ("ğŸ‹ï¸", "åŠ›é‡è®­ç»ƒ"),
    401: ("ğŸ‹ï¸", "åŠ›é‡è®­ç»ƒ"),
    300: ("ğŸŠ", "æ¸¸æ³³"),
    10100: ("ğŸš¶", "å¥æ­¥"),
    10300: ("ğŸ§˜", "ç‘œä¼½"),
}

PACE_ZONE_LABELS = ["E è½»æ¾", "M é©¬æ‹‰æ¾", "T ä¹³é…¸é˜ˆ", "I é—´æ­‡", "R é‡å¤", "å…¶ä»–è·‘", "å…¶ä»–è¿åŠ¨"]
HR_ZONE_LABELS = ["Zone 1", "Zone 2", "Zone 3", "Zone 4", "Zone 5"]

PLOTLY_LAYOUT = dict(
    paper_bgcolor="rgba(0,0,0,0)",
    plot_bgcolor="rgba(0,0,0,0)",
    font_color="#fafafa",
    margin=dict(l=40, r=20, t=30, b=30),
    legend=dict(orientation="h", y=-0.15),
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=60)
def load_json(name: str):
    p = DATA_DIR / name
    if not p.exists():
        return None
    with open(p, "r", encoding="utf-8") as f:
        return json.load(f)


def fmt_pace(seconds_per_km: float) -> str:
    if not seconds_per_km or seconds_per_km <= 0:
        return "--"
    m = int(seconds_per_km) // 60
    s = int(seconds_per_km) % 60
    return f"{m}'{s:02d}\""


def fmt_duration(seconds: int) -> str:
    if not seconds or seconds <= 0:
        return "--"
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    if h > 0:
        return f"{h}:{m:02d}:{s:02d}"
    return f"{m:02d}:{s:02d}"


def fmt_distance(meters: float) -> str:
    if not meters or meters <= 0:
        return "--"
    km = meters / 1000
    if km >= 10:
        return f"{km:.1f}km"
    return f"{km:.2f}km"


def fmt_date(d: int) -> str:
    s = str(d)
    return f"{s[:4]}-{s[4:6]}-{s[6:]}"


def parse_date(d: int) -> date:
    s = str(d)
    return date(int(s[:4]), int(s[4:6]), int(s[6:]))


def sport_icon(sport_type: int) -> str:
    return SPORT_TYPE_MAP.get(sport_type, ("ğŸ…", "å…¶ä»–"))[0]


def sport_name(sport_type: int) -> str:
    return SPORT_TYPE_MAP.get(sport_type, ("ğŸ…", "å…¶ä»–"))[1]


def tl_ratio_state_text(state: int) -> tuple[str, str]:
    mapping = {
        1: ("ä¸¥é‡ä¸è¶³", "ğŸ”´"),
        2: ("ä¸è¶³", "ğŸŸ "),
        3: ("ç»´æŒ", "ğŸŸ¡"),
        4: ("é«˜æ•ˆ", "ğŸŸ¢"),
        5: ("è¿‡åº¦", "ğŸ”´"),
    }
    return mapping.get(state, ("æœªçŸ¥", "âšª"))


def fatigue_state_text(state: int) -> tuple[str, str]:
    mapping = {
        1: ("éå¸¸è½»æ¾", "ğŸŸ¢"),
        2: ("è½»æ¾", "ğŸŸ¢"),
        3: ("é€‚ä¸­", "ğŸŸ¡"),
        4: ("ç–²åŠ³", "ğŸŸ "),
        5: ("éå¸¸ç–²åŠ³", "ğŸ”´"),
    }
    return mapping.get(state, ("æœªçŸ¥", "âšª"))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Import plan to COROS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COROS_LOGIN_URL = "https://t.coros.com/login"
SECRETS_FILE = Path(__file__).parent / ".streamlit" / "secrets.toml"


def parse_curl_credentials(curl_text: str) -> dict | None:
    """Extract accesstoken, cookies, and userId from a pasted curl command."""
    creds: dict[str, str] = {}

    token_m = re.search(r"-H\s+['\"]accesstoken:\s*([^'\"]+)['\"]", curl_text)
    if token_m:
        creds["access_token"] = token_m.group(1).strip()

    cookie_m = re.search(r"-b\s+['\"]([^'\"]+)['\"]", curl_text)
    if cookie_m:
        cookie_str = cookie_m.group(1)
        for name, key in [("_c_WBKFRo", "cookie_wbkfro"), ("CPL-coros-region", "cookie_region")]:
            m = re.search(rf"{re.escape(name)}=([^;\s]+)", cookie_str)
            if m:
                creds[key] = m.group(1).strip()

    yf_m = re.search(r"""yfheader:\s*['"]\s*(\{[^}]+\})""", curl_text)
    if yf_m:
        try:
            yf = json.loads(yf_m.group(1))
            if "userId" in yf:
                creds["user_id"] = str(yf["userId"])
        except (json.JSONDecodeError, KeyError):
            pass

    return creds if "access_token" in creds else None


def save_secrets_toml(creds: dict):
    """Write updated credentials to .streamlit/secrets.toml."""
    user_id = creds.get("user_id", os.environ.get("COROS_USER_ID", ""))
    region = creds.get("cookie_region", os.environ.get("COROS_COOKIE_REGION", "2"))
    base_url = os.environ.get("COROS_BASE_URL", "https://teamcnapi.coros.com")

    content = (
        "[coros]\n"
        f'access_token = "{creds.get("access_token", "")}"\n'
        f'user_id = "{user_id}"\n'
        f'cookie_wbkfro = "{creds.get("cookie_wbkfro", "")}"\n'
        f'cookie_region = "{region}"\n'
        f'base_url = "{base_url}"\n'
    )
    SECRETS_FILE.parent.mkdir(parents=True, exist_ok=True)
    SECRETS_FILE.write_text(content, encoding="utf-8")


def apply_credentials(creds: dict):
    """Push parsed credentials into env vars, persist to secrets.toml, and clear sync flag."""
    for env_key, cred_key in [
        ("COROS_ACCESS_TOKEN", "access_token"),
        ("COROS_COOKIE_WBKFRO", "cookie_wbkfro"),
        ("COROS_COOKIE_REGION", "cookie_region"),
        ("COROS_USER_ID", "user_id"),
    ]:
        if cred_key in creds:
            os.environ[env_key] = creds[cred_key]

    save_secrets_toml(creds)
    st.session_state.pop("data_synced", None)
    st.session_state.pop("token_invalid", None)
    load_json.clear()


def show_token_invalid_guide(key_suffix: str = "main"):
    """Display login link, curl paste box, and auto-parse credentials."""
    st.error("Access Token å·²å¤±æ•ˆï¼Œè¯·é‡æ–°ç™»å½•è·å–")
    st.markdown(f"""
#### ğŸ”‘ æ­¥éª¤ 1ï¼š[æ‰“å¼€ COROS ç™»å½•é¡µ]({COROS_LOGIN_URL})ï¼Œç”¨ COROS App æ‰«ç ç™»å½•

#### ğŸ“‹ æ­¥éª¤ 2ï¼šç™»å½•æˆåŠŸåå¤åˆ¶ä¸€æ¡ cURL
1. ç™»å½•æˆåŠŸåé¡µé¢ä¼šè·³è½¬åˆ° COROS ä¸»é¡µï¼ˆå¦‚æœªè·³è½¬ï¼Œæ‰‹åŠ¨è®¿é—® [t.coros.com](https://t.coros.com)ï¼‰
2. **å…ˆæŒ‰ F12** æ‰“å¼€å¼€å‘è€…å·¥å…· â†’ åˆ‡åˆ° **Network** æ ‡ç­¾
3. **å†æŒ‰ Cmd+R åˆ·æ–°é¡µé¢**ï¼ˆNetwork åªè®°å½•æ‰“å¼€åçš„è¯·æ±‚ï¼‰
4. åœ¨è¯·æ±‚åˆ—è¡¨ä¸­æ‰¾åˆ°ä»»æ„ `teamcnapi.coros.com` å¼€å¤´çš„è¯·æ±‚
5. **å³é”®è¯¥è¯·æ±‚ â†’ Copy â†’ Copy as cURL**

#### ğŸ“¥ æ­¥éª¤ 3ï¼šç²˜è´´åˆ°ä¸‹æ–¹è¾“å…¥æ¡†
""")

    curl_text = st.text_area(
        "ç²˜è´´ cURL å‘½ä»¤",
        height=120,
        placeholder="curl 'https://teamcnapi.coros.com/...' -H 'accesstoken: ...' -b '...' ...",
        key=f"curl_input_{key_suffix}",
    )

    if st.button("ğŸ”„ æ›´æ–°å‡­æ®å¹¶é‡æ–°åŒæ­¥", type="primary", key=f"apply_curl_{key_suffix}"):
        if not curl_text or not curl_text.strip():
            st.warning("è¯·å…ˆç²˜è´´ cURL å‘½ä»¤")
            return
        creds = parse_curl_credentials(curl_text)
        if creds:
            apply_credentials(creds)
            token = creds["access_token"]
            st.success(f"å‡­æ®å·²æ›´æ–°ï¼Token: {token[:8]}...{token[-4:]}")
            st.rerun()
        else:
            st.error("æ— æ³•ä» cURL ä¸­è§£æå‡º accesstokenï¼Œè¯·ç¡®è®¤ç²˜è´´çš„æ˜¯å®Œæ•´çš„ curl å‘½ä»¤")


def import_plan_to_coros() -> tuple[bool, str]:
    """Parse update plan body from save_plan.json, transform to add format, create new plan."""
    save_file = DATA_DIR / "save_plan.json"
    if not save_file.exists():
        return False, "data/save_plan.json æ–‡ä»¶ä¸å­˜åœ¨"

    content = save_file.read_text(encoding="utf-8")

    if "-- ä¿®æ”¹è®¡åˆ’" in content:
        update_section = content.split("-- ä¿®æ”¹è®¡åˆ’", 1)[1]
    else:
        update_section = content

    match = re.search(r"--data-raw \$?'(.+)'\s*$", update_section, re.MULTILINE)
    if not match:
        return False, "æ— æ³•ä» save_plan.json è§£æä¿®æ”¹è®¡åˆ’çš„è¯·æ±‚ä½“"

    raw_json = match.group(1)
    raw_json = raw_json.replace("\\'", "'")
    raw_json = raw_json.replace("\\\\", "\\")

    try:
        update_data = json.loads(raw_json)
    except json.JSONDecodeError as e:
        return False, f"JSON è§£æé”™è¯¯: {e}"

    now = datetime.now()
    plan_name = f"è®­ç»ƒè®¡åˆ’_{now.strftime('%m%d_%H%M%S')}"

    # --- Entities: keep only add-API fields ---
    entities = []
    for e in update_data.get("entities", []):
        entities.append({
            "happenDay": e.get("happenDay", ""),
            "idInPlan": int(e["idInPlan"]) if e.get("idInPlan") is not None else 0,
            "sortNo": e.get("sortNo", 0),
            "dayNo": e.get("dayNo", 0),
            "sortNoInPlan": e.get("sortNoInPlan", 0),
            "sortNoInSchedule": e.get("sortNoInSchedule", 0),
        })

    # --- Programs: strip server-generated fields ---
    PROG_STRIP = {
        "id", "planId", "authorId", "createTimestamp", "deleted",
        "estimatedDistance", "headPic", "nickname", "status",
        "userId", "star", "isTargetTypeConsistent", "planIdIndex",
        "sex", "profile", "shareUrl", "thirdPartyId",
        "videoCoverUrl", "videoUrl", "onlyId", "fastIntensityTypeName",
    }
    EX_STRIP = {"userId", "status", "videoInfos"}

    programs = []
    for prog in update_data.get("programs", []):
        clean = {}
        for k, v in prog.items():
            if k in PROG_STRIP:
                continue
            if k == "idInPlan":
                clean[k] = int(v) if isinstance(v, str) else v
            elif k == "exercises":
                exs = []
                for idx, ex in enumerate(v):
                    cex = {ek: ev for ek, ev in ex.items() if ek not in EX_STRIP}
                    cex["id"] = idx + 1
                    exs.append(cex)
                clean[k] = exs
            elif k == "exerciseBarChart":
                charts = []
                for idx, ch in enumerate(v):
                    c = dict(ch)
                    c["exerciseId"] = str(idx + 1)
                    charts.append(c)
                clean[k] = charts
            else:
                clean[k] = v
        clean.setdefault("version", 0)
        clean["cardType"] = "program"
        clean["dataType"] = "program"
        programs.append(clean)

    version_objects = []
    for vo in update_data.get("versionObjects", []):
        version_objects.append({"id": vo["id"], "status": vo.get("status", 1)})
    if not version_objects and programs:
        version_objects = [{"id": programs[0].get("idInPlan", 1), "status": 1}]

    add_body = {
        "name": plan_name,
        "overview": update_data.get("overview", ""),
        "entities": entities,
        "programs": programs,
        "weekStages": [],
        "maxIdInPlan": update_data.get("maxIdInPlan", 1),
        "totalDay": update_data.get("totalDay", 28),
        "unit": update_data.get("unit", 0),
        "sourceId": update_data.get("sourceId", ""),
        "sourceUrl": update_data.get("sourceUrl", ""),
        "minWeeks": update_data.get("minWeeks", 1),
        "maxWeeks": update_data.get("maxWeeks", 4),
        "region": update_data.get("region", 2),
        "pbVersion": update_data.get("pbVersion", 2),
        "versionObjects": version_objects,
    }

    # --- Call COROS add API ---
    access_token = os.environ.get("COROS_ACCESS_TOKEN", "")
    user_id = os.environ.get("COROS_USER_ID", "")
    cookie_wbkfro = os.environ.get("COROS_COOKIE_WBKFRO", "")
    cookie_region = os.environ.get("COROS_COOKIE_REGION", "2")
    base_url = os.environ.get("COROS_BASE_URL", "https://teamcnapi.coros.com")

    if not access_token or not user_id:
        return False, "COROS å‡­æ®æœªé…ç½®ï¼ˆéœ€è¦ access_token å’Œ user_idï¼‰"

    headers = {
        "accept": "application/json, text/plain, */*",
        "accesstoken": access_token,
        "content-type": "application/json",
        "origin": "https://t.coros.com",
        "referer": "https://t.coros.com/",
        "yfheader": json.dumps({"userId": user_id}),
    }
    cookies = {
        "_c_WBKFRo": cookie_wbkfro,
        "CPL-coros-region": cookie_region,
        "CPL-coros-token": access_token,
    }

    try:
        resp = requests.post(
            f"{base_url}/training/plan/add",
            headers=headers,
            cookies=cookies,
            json=add_body,
            timeout=30,
        )
        result = resp.json()
        if resp.status_code == 200 and str(result.get("result")) == "0000":
            data = result.get("data", "")
            plan_id = data.get("id", "") if isinstance(data, dict) else data
            return True, f"è®¡åˆ’ã€Œ{plan_name}ã€åˆ›å»ºæˆåŠŸï¼(planId: {plan_id})"

        resp_text = json.dumps(result, ensure_ascii=False)
        is_token_invalid = (
            "token" in resp_text.lower() and "invalid" in resp_text.lower()
        ) or str(result.get("result")) in ("1003", "1004")
        if is_token_invalid:
            return False, "__TOKEN_INVALID__"
        return False, f"API é”™è¯¯ ({resp.status_code}): {resp_text[:500]}"
    except requests.RequestException as e:
        return False, f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}"
    except Exception as e:
        return False, f"å¯¼å…¥å¤±è´¥: {e}"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Page config
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="COROS è®­ç»ƒä»ªè¡¨æ¿", page_icon="ğŸƒ", layout="wide")
st.markdown('<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">', unsafe_allow_html=True)
st.markdown("""<style>
    .block-container { padding-top: 2.5rem; padding-bottom: 0; }
    header[data-testid="stHeader"] { background: #0e1117; }
    div[data-testid='stMetric'] {
        background: #1a1f2e; padding: 14px 18px; border-radius: 10px;
    }
    div[data-testid='stMetricLabel'] > div > div > p {
        font-size: 1rem !important; color: #e2e8f0 !important;
    }
    div[data-testid='stMetricValue'] > div {
        font-size: 1.8rem !important; font-weight: 700 !important;
    }
    div[data-testid='stMetricDelta'] > div {
        font-size: 0.85rem !important;
    }

    /* Tabs â€” cover all Streamlit versions */
    .stTabs [data-baseweb="tab-list"] {
        gap: 0; background: #111827; border-radius: 10px; padding: 4px;
    }
    .stTabs [data-baseweb="tab-list"] button,
    .stTabs [data-baseweb="tab-list"] [data-baseweb="tab"] {
        font-size: 1.05rem !important; font-weight: 600 !important;
        padding: 12px 28px !important; border-radius: 8px !important;
        color: #94a3b8 !important; border: none !important;
        background: transparent !important;
    }
    .stTabs [data-baseweb="tab-list"] button[aria-selected="true"],
    .stTabs [data-baseweb="tab-list"] [data-baseweb="tab"][aria-selected="true"] {
        color: #00d4aa !important;
        background: rgba(0,212,170,0.12) !important;
    }
    .stTabs [data-baseweb="tab-list"] button:hover,
    .stTabs [data-baseweb="tab-list"] [data-baseweb="tab"]:hover {
        color: #f1f5f9 !important;
        background: rgba(255,255,255,0.06) !important;
    }
    /* hide the default underline indicator */
    .stTabs [data-baseweb="tab-highlight"] {
        background-color: #00d4aa !important; height: 3px !important;
    }
    .stTabs [data-baseweb="tab-border"] {
        display: none;
    }

    .todo-done { text-decoration: line-through; color: #6b7280; }

    /* â”€â”€ Mobile responsive â”€â”€ */
    @media (max-width: 768px) {
        .block-container {
            padding-top: 1.5rem;
            padding-left: 0.5rem !important;
            padding-right: 0.5rem !important;
        }
        /* Default: wrap columns, 2 per row for text/metrics */
        [data-testid="stHorizontalBlock"] {
            flex-wrap: wrap !important;
            gap: 0.3rem !important;
        }
        [data-testid="stHorizontalBlock"] > * {
            width: 48% !important;
            flex: 0 0 48% !important;
            min-width: 48% !important;
            max-width: 48% !important;
        }
        /* Rows containing charts â†’ single column full width */
        [data-testid="stHorizontalBlock"]:has(.js-plotly-plot) > *,
        [data-testid="stHorizontalBlock"]:has([data-testid="stDataFrame"]) > *,
        [data-testid="stHorizontalBlock"]:has(.stPlotlyChart) > * {
            width: 100% !important;
            flex: 0 0 100% !important;
            min-width: 100% !important;
            max-width: 100% !important;
        }
        /* 2-child rows: keep natural widths (checkbox+info) */
        [data-testid="stHorizontalBlock"]:has(> :nth-child(2):last-child) {
            flex-wrap: nowrap !important;
        }
        [data-testid="stHorizontalBlock"]:has(> :nth-child(2):last-child) > * {
            width: auto !important;
            flex: unset !important;
            min-width: 0 !important;
            max-width: none !important;
        }
        /* Smaller metrics */
        div[data-testid='stMetric'] { padding: 10px 12px; }
        div[data-testid='stMetricValue'] > div { font-size: 1.3rem !important; }
        div[data-testid='stMetricLabel'] > div > div > p { font-size: 0.85rem !important; }
        div[data-testid='stMetricDelta'] > div { font-size: 0.75rem !important; }
        /* Tabs: scroll horizontally */
        .stTabs [data-baseweb="tab-list"] {
            overflow-x: auto !important;
            -webkit-overflow-scrolling: touch;
            flex-wrap: nowrap !important;
            padding: 2px;
        }
        .stTabs [data-baseweb="tab-list"] button,
        .stTabs [data-baseweb="tab-list"] [data-baseweb="tab"] {
            font-size: 0.85rem !important;
            padding: 8px 14px !important;
            white-space: nowrap !important;
        }
        /* Tables & charts overflow */
        [data-testid="stDataFrame"] { overflow-x: auto !important; }
        .js-plotly-plot, .plotly { max-width: 100% !important; overflow-x: hidden !important; }
    }

    /* Tablets */
    @media (min-width: 769px) and (max-width: 1024px) {
        [data-testid="stHorizontalBlock"] { flex-wrap: wrap !important; }
        [data-testid="stHorizontalBlock"] > * {
            width: 48% !important; flex: 0 0 48% !important; min-width: 48% !important;
        }
        [data-testid="stHorizontalBlock"]:has(> :nth-child(2):last-child) { flex-wrap: nowrap !important; }
        [data-testid="stHorizontalBlock"]:has(> :nth-child(2):last-child) > * {
            width: auto !important; flex: unset !important;
            min-width: 0 !important; max-width: none !important;
        }
    }
</style>""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Auto-sync on startup (once per session)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "data_synced" not in st.session_state:
    try:
        coros_secrets = st.secrets.get("coros", {})
        if coros_secrets:
            os.environ.setdefault("COROS_ACCESS_TOKEN", str(coros_secrets.get("access_token", "")))
            os.environ.setdefault("COROS_USER_ID", str(coros_secrets.get("user_id", "")))
            os.environ.setdefault("COROS_COOKIE_WBKFRO", str(coros_secrets.get("cookie_wbkfro", "")))
            os.environ.setdefault("COROS_COOKIE_REGION", str(coros_secrets.get("cookie_region", "2")))
            os.environ.setdefault("COROS_BASE_URL", str(coros_secrets.get("base_url", "https://teamcnapi.coros.com")))
    except Exception:
        pass

    with st.spinner("æ­£åœ¨åŒæ­¥ COROS æ•°æ®..."):
        try:
            import fetch_coros_data as fcd
            fcd.CONFIG["access_token"] = os.environ.get("COROS_ACCESS_TOKEN", "")
            _tok = fcd.CONFIG["access_token"]
            fcd.CONFIG["cookies"]["_c_WBKFRo"] = os.environ.get("COROS_COOKIE_WBKFRO", "")
            fcd.CONFIG["cookies"]["CPL-coros-token"] = _tok
            fcd.CONFIG["cookies"]["CPL-coros-region"] = os.environ.get("COROS_COOKIE_REGION", "2")
            fcd.CONFIG["user_id"] = os.environ.get("COROS_USER_ID", "")
            fcd.CONFIG["base_url"] = os.environ.get("COROS_BASE_URL", "https://teamcnapi.coros.com")

            if not _tok:
                st.warning("æœªé…ç½® COROS å‡­æ®ï¼Œè·³è¿‡åŒæ­¥")
            else:
                fcd.DATA_DIR.mkdir(parents=True, exist_ok=True)
                fcd.sync_activities()
                fcd.sync_analyse()
                fcd.sync_dashboard()
                fcd._save_meta(fcd._load_meta())
                st.toast("æ•°æ®åŒæ­¥å®Œæˆ", icon="âœ…")
        except fcd.TokenInvalidError:
            st.session_state.token_invalid = True
        except Exception as e:
            if "token" in str(e).lower() and "invalid" in str(e).lower():
                st.session_state.token_invalid = True
            else:
                st.warning(f"åŒæ­¥å¼‚å¸¸: {e}ï¼Œä½¿ç”¨æœ¬åœ°ç¼“å­˜")
    st.session_state.data_synced = True

# Show token guide outside the sync block so button clicks survive reruns
if st.session_state.get("token_invalid"):
    show_token_invalid_guide(key_suffix="sync")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Load data
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
activities_raw = load_json("activities.json") or []
analyse_raw = load_json("analyse.json") or {}
dashboard_raw = load_json("dashboard.json") or {}

if not activities_raw:
    st.warning("æš‚æ— æ•°æ®ã€‚å¦‚é¦–æ¬¡éƒ¨ç½²è¯·åœ¨ Streamlit Cloud Secrets ä¸­é…ç½® COROS å‡­æ®ååˆ·æ–°é¡µé¢ã€‚")
    st.code("""
# .streamlit/secrets.toml (æˆ– Streamlit Cloud â†’ Settings â†’ Secrets)
[coros]
access_token = "YOUR_COROS_ACCESS_TOKEN"
user_id = "YOUR_COROS_USER_ID"
cookie_wbkfro = "YOUR_COOKIE_VALUE"
cookie_region = "2"
    """.strip(), language="toml")
    st.stop()

day_list = analyse_raw.get("dayList", [])
summary_info_analyse = analyse_raw.get("summaryInfo", {})
sport_statistic = analyse_raw.get("sportStatistic", [])
week_list = analyse_raw.get("weekList", [])
tl_intensity = analyse_raw.get("tlIntensity", {})
t7day_list = analyse_raw.get("t7dayList", [])

dash_summary = dashboard_raw.get("summaryInfo", {})
dash_current_week = dashboard_raw.get("currentWeekRecord", {})
dash_sport_data = dashboard_raw.get("sportDataList", [])
dash_detail_list = dashboard_raw.get("detailList", [])
dash_target_list = dashboard_raw.get("targetList", [])


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tabs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab_dashboard, tab_analysis, tab_activities, tab_plan = st.tabs(
    ["ğŸ“Š ä»ªè¡¨æ¿", "ğŸ“ˆ æ•°æ®åˆ†æ", "ğŸ“‹ æ´»åŠ¨åˆ—è¡¨", "ğŸ“… è®­ç»ƒè®¡åˆ’"]
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 1 â€“ Dashboard
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab_dashboard:
    # Row 1: headline metrics
    latest_day = day_list[-1] if day_list else {}
    vo2max = latest_day.get("vo2max") or 0
    for d in reversed(day_list):
        if d.get("vo2max"):
            vo2max = d["vo2max"]
            break
    stamina = latest_day.get("staminaLevel") or 0
    for d in reversed(day_list):
        if d.get("staminaLevel"):
            stamina = d["staminaLevel"]
            break
    lthr = 0
    ltsp = 0
    for d in reversed(day_list):
        if d.get("lthr"):
            lthr = d["lthr"]
            ltsp = d.get("ltsp", 0)
            break

    tl_ratio = dash_summary.get("trainingLoadRatio", 0)
    tl_ratio_st = dash_summary.get("trainingLoadRatioState", 0)
    tl_text, tl_emoji = tl_ratio_state_text(tl_ratio_st)
    tired_state = dash_summary.get("tiredRateNewState", 0)
    tired_text, tired_emoji = fatigue_state_text(tired_state)

    c1, c2, c3, c4, c5, c6 = st.columns(6)
    c1.metric("VO2max", f"{vo2max}")
    c2.metric("è·‘æ­¥èƒ½åŠ›", f"{stamina}")
    c3.metric("è®­ç»ƒè´Ÿè·æ¯”", f"{tl_ratio*100:.0f}%", f"{tl_emoji} {tl_text}")
    c4.metric("ç–²åŠ³çŠ¶æ€", f"{tired_text}", f"ATI {dash_summary.get('ati','--')} / CTI {dash_summary.get('cti','--')}")
    c5.metric("ä¹³é…¸é˜ˆå¿ƒç‡", f"{lthr} bpm")
    c6.metric("ä¹³é…¸é˜ˆé…é€Ÿ", fmt_pace(ltsp))

    st.divider()

    # Row 2: 7-day load chart + recent activities + this week summary
    col_load, col_recent, col_week = st.columns([1.2, 2, 1.2])

    with col_load:
        st.subheader("7 å¤©è®­ç»ƒè´Ÿè·")
        if dash_detail_list:
            df_detail = pd.DataFrame(dash_detail_list)
            df_detail["date_str"] = df_detail["happenDay"].apply(fmt_date)
            fig = go.Figure()
            fig.add_bar(
                x=df_detail["date_str"],
                y=df_detail["trainingLoad"],
                marker_color="#00d4aa",
                name="è®­ç»ƒè´Ÿè·",
            )
            if "trainingLoadTarget" in df_detail.columns:
                fig.add_scatter(
                    x=df_detail["date_str"],
                    y=df_detail["trainingLoadTarget"],
                    mode="lines+markers",
                    line=dict(color="#ff6b6b", dash="dash"),
                    name="ç›®æ ‡",
                )
            fig.update_layout(**PLOTLY_LAYOUT, height=250, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)

    with col_recent:
        st.subheader("æœ€è¿‘è¿åŠ¨")
        recent = dash_sport_data[:7] if dash_sport_data else activities_raw[:7]
        rows = []
        for a in recent:
            rows.append({
                "æ—¥æœŸ": fmt_date(a.get("happenDay", a.get("date", 0))),
                "ç±»å‹": sport_icon(a.get("sportType", 0)),
                "åç§°": a.get("name", sport_name(a.get("sportType", 0))),
                "è·ç¦»": fmt_distance(a.get("distance", 0)),
                "æ—¶é—´": fmt_duration(a.get("duration", a.get("totalTime", 0))),
                "å¿ƒç‡": a.get("avgHeartRate", a.get("avgHr", "--")),
                "è´Ÿè·": a.get("trainingLoad", "--"),
            })
        if rows:
            st.dataframe(pd.DataFrame(rows), width="stretch", hide_index=True, height=290)

    with col_week:
        st.subheader("æœ¬å‘¨æ±‡æ€»")
        dist_rec = dash_current_week.get("distanceRecord", {})
        dur_rec = dash_current_week.get("durationRecord", {})
        tl_rec = dash_current_week.get("tlRecord", {})
        st.metric("è·ç¦»", fmt_distance(dist_rec.get("totalValue", 0)),
                  f"ç›®æ ‡ {fmt_distance(dist_rec.get('totalTarget', 0))}  ({dist_rec.get('percentage', 0):.0f}%)")
        st.metric("æ—¶é—´", fmt_duration(int(dur_rec.get("totalValue", 0))),
                  f"ç›®æ ‡ {fmt_duration(int(dur_rec.get('totalTarget', 0)))}  ({dur_rec.get('percentage', 0):.0f}%)")
        st.metric("è®­ç»ƒè´Ÿè·", tl_rec.get("totalValue", 0),
                  f"ç›®æ ‡ {tl_rec.get('totalTarget', 0)}  ({tl_rec.get('percentage', 0):.0f}%)")

    st.divider()

    # Row 3: HRV + Resting HR + Personal records
    col_hrv, col_rhr, col_records = st.columns(3)

    with col_hrv:
        st.subheader("HRV è¯„ä¼°")
        hrv_vals = [d.get("avgSleepHrv") for d in day_list if d.get("avgSleepHrv")]
        if hrv_vals:
            latest_hrv = hrv_vals[-1]
            base_hrv = [d.get("sleepHrvBase") for d in day_list if d.get("sleepHrvBase")]
            base = base_hrv[-1] if base_hrv else 0
            st.metric("æœ€è¿‘ HRV", f"{latest_hrv} ms", f"åŸºçº¿ {base} ms")
            df_hrv = pd.DataFrame([
                {"æ—¥æœŸ": fmt_date(d["happenDay"]), "HRV": d["avgSleepHrv"]}
                for d in day_list if d.get("avgSleepHrv")
            ])
            fig = px.line(df_hrv, x="æ—¥æœŸ", y="HRV", height=200)
            fig.update_layout(**PLOTLY_LAYOUT)
            fig.update_traces(line_color="#a78bfa")
            st.plotly_chart(fig, use_container_width=True)

    with col_rhr:
        st.subheader("é™æ¯å¿ƒç‡")
        rhr_vals = [(d["happenDay"], d["testRhr"]) for d in day_list if d.get("testRhr")]
        if rhr_vals:
            latest_rhr = rhr_vals[-1][1]
            min_rhr = min(v for _, v in rhr_vals)
            st.metric("æœ€è¿‘ RHR", f"{latest_rhr} bpm", f"æœ€ä½ {min_rhr} bpm")
            df_rhr = pd.DataFrame([
                {"æ—¥æœŸ": fmt_date(hd), "RHR": rhr} for hd, rhr in rhr_vals
            ])
            fig = px.line(df_rhr, x="æ—¥æœŸ", y="RHR", height=200)
            fig.update_layout(**PLOTLY_LAYOUT)
            fig.update_traces(line_color="#f87171")
            st.plotly_chart(fig, use_container_width=True)

    with col_records:
        st.subheader("è¿åŠ¨ç±»å‹ç»Ÿè®¡")
        if sport_statistic:
            rows = []
            for s in sport_statistic:
                st_type = s.get("sportType", 0)
                if st_type == 65535:
                    continue
                rows.append({
                    "ç±»å‹": sport_name(st_type),
                    "æ¬¡æ•°": s.get("count", 0),
                    "è·ç¦»": fmt_distance(s.get("distance", 0)),
                    "æ—¶é—´": fmt_duration(s.get("duration", 0)),
                    "è´Ÿè·": s.get("trainingLoad", 0),
                })
            if rows:
                st.dataframe(pd.DataFrame(rows), width="stretch", hide_index=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 2 â€“ Data Analysis
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab_analysis:
    if not day_list:
        st.warning("æ— åˆ†ææ•°æ®")
    else:
        df_days = pd.DataFrame(day_list)
        df_days["date_str"] = df_days["happenDay"].apply(fmt_date)

        ncols = st.radio("æ¯è¡Œå›¾è¡¨æ•°", [1, 2, 3, 4], horizontal=True, index=1, key="analysis_cols")
        chart_h = {1: 380, 2: 320, 3: 280, 4: 240}[ncols]

        def _render_chart(fig):
            st.plotly_chart(fig, use_container_width=True)

        # â”€â”€ chart builders (lazy list) â”€â”€
        def chart_training_load():
            st.markdown("**æ¯æ—¥è®­ç»ƒè´Ÿè·**")
            fig = go.Figure()
            fig.add_bar(x=df_days["date_str"], y=df_days["trainingLoad"],
                        marker_color="#00d4aa", name="è®­ç»ƒè´Ÿè·")
            if "recomendTlMax" in df_days.columns:
                fig.add_scatter(x=df_days["date_str"], y=df_days["recomendTlMax"],
                                mode="lines", line=dict(color="rgba(255,107,107,0.4)", dash="dot"), name="å»ºè®®ä¸Šé™")
                fig.add_scatter(x=df_days["date_str"], y=df_days["recomendTlMin"],
                                mode="lines", line=dict(color="rgba(107,203,119,0.4)", dash="dot"), name="å»ºè®®ä¸‹é™")
            fig.update_layout(**PLOTLY_LAYOUT, height=chart_h)
            _render_chart(fig)

        def chart_vo2max():
            st.markdown("**æœ€å¤§æ‘„æ°§é‡ (VO2max)**")
            vo2_data = df_days[df_days["vo2max"] > 0]
            if not vo2_data.empty:
                fig = px.line(vo2_data, x="date_str", y="vo2max", height=chart_h, markers=True)
                fig.update_traces(line_color="#60a5fa")
                fig.update_layout(**PLOTLY_LAYOUT, yaxis_title="VO2max")
                _render_chart(fig)
            else:
                st.info("æ—  VO2max æ•°æ®")

        def chart_rhr():
            st.markdown("**é™æ¯å¿ƒç‡è¶‹åŠ¿**")
            rhr_data = df_days[df_days["rhr"] > 0] if "rhr" in df_days.columns else pd.DataFrame()
            if not rhr_data.empty:
                fig = go.Figure()
                fig.add_scatter(x=rhr_data["date_str"], y=rhr_data["rhr"],
                                mode="lines+markers", line_color="#f87171", name="RHR")
                if "testRhr" in rhr_data.columns:
                    test_rhr = rhr_data[rhr_data["testRhr"] > 0]
                    if not test_rhr.empty:
                        fig.add_scatter(x=test_rhr["date_str"], y=test_rhr["testRhr"],
                                        mode="lines", line=dict(color="#fbbf24", dash="dash"), name="æµ‹è¯•RHR")
                fig.update_layout(**PLOTLY_LAYOUT, height=chart_h)
                _render_chart(fig)

        def chart_7d_28d():
            st.markdown("**7å¤© / 28å¤© è®­ç»ƒè´Ÿè·**")
            fig = go.Figure()
            fig.add_scatter(x=df_days["date_str"], y=df_days["t7d"], mode="lines", line_color="#00d4aa", name="7å¤©è´Ÿè·")
            fig.add_scatter(x=df_days["date_str"], y=df_days["t28d"], mode="lines", line_color="#60a5fa", name="28å¤©è´Ÿè·")
            fig.update_layout(**PLOTLY_LAYOUT, height=chart_h)
            _render_chart(fig)

        def chart_weekly_vol():
            st.markdown("**å‘¨è®­ç»ƒé‡**")
            dist_weeks = analyse_raw.get("record", {}).get("distanceRecord", {}).get("detailList", [])
            if dist_weeks:
                df_w = pd.DataFrame(dist_weeks)
                df_w["week_label"] = df_w["firstDayOfWeek"].apply(lambda x: fmt_date(x) if x else "")
                df_w["km"] = df_w["value"] / 1000
                fig = go.Figure()
                fig.add_bar(x=df_w["week_label"], y=df_w["km"], marker_color="#00d4aa", name="è·ç¦»(km)")
                fig.update_layout(**PLOTLY_LAYOUT, height=chart_h, yaxis_title="km")
                _render_chart(fig)

        def chart_intensity():
            st.markdown("**4 å‘¨å¼ºåº¦åˆ†å¸ƒ**")
            tl_detail = tl_intensity.get("detailList", [])
            if tl_detail:
                df_tl = pd.DataFrame(tl_detail)
                df_tl["period"] = df_tl.apply(
                    lambda r: f"{fmt_date(r['firstDayOfWeek'])}~{fmt_date(r['lastDayInWeek'])}", axis=1)
                fig = go.Figure()
                fig.add_bar(x=df_tl["period"], y=df_tl["periodLowValue"], name="ä½å¼ºåº¦", marker_color="#22c55e")
                fig.add_bar(x=df_tl["period"], y=df_tl["periodMediumValue"], name="ä¸­å¼ºåº¦", marker_color="#eab308")
                fig.add_bar(x=df_tl["period"], y=df_tl["periodHighValue"], name="é«˜å¼ºåº¦", marker_color="#ef4444")
                fig.update_layout(**PLOTLY_LAYOUT, barmode="stack", height=chart_h)
                _render_chart(fig)

        def chart_pace_zone():
            st.markdown("**é…é€ŸåŒºé—´åˆ†å¸ƒ**")
            dis_area = summary_info_analyse.get("disAreaList", [])
            if dis_area:
                fig = go.Figure(go.Pie(
                    labels=PACE_ZONE_LABELS[:len(dis_area)], values=[a["ratio"] for a in dis_area], hole=0.45,
                    marker_colors=["#22c55e", "#3b82f6", "#eab308", "#f97316", "#ef4444", "#8b5cf6", "#6b7280"]))
                fig.update_layout(**PLOTLY_LAYOUT, height=chart_h)
                _render_chart(fig)

        def chart_hr_zone():
            st.markdown("**å¿ƒç‡åŒºé—´åˆ†å¸ƒ**")
            hr_area = summary_info_analyse.get("hrDisAreaList", [])
            if hr_area:
                fig = go.Figure(go.Pie(
                    labels=HR_ZONE_LABELS[:len(hr_area)], values=[a["ratio"] for a in hr_area], hole=0.45,
                    marker_colors=["#94a3b8", "#22c55e", "#eab308", "#f97316", "#ef4444"]))
                fig.update_layout(**PLOTLY_LAYOUT, height=chart_h)
                _render_chart(fig)

        def chart_fatigue():
            st.markdown("**ç–²åŠ³è¶‹åŠ¿ (TIB)**")
            if "tiredRateNew" in df_days.columns:
                fig = go.Figure()
                colors = df_days["tiredRateNew"].apply(
                    lambda v: "#ef4444" if v > 30 else "#eab308" if v > 10 else "#22c55e").tolist()
                fig.add_bar(x=df_days["date_str"], y=df_days["tiredRateNew"], marker_color=colors, name="ç–²åŠ³æŒ‡æ•°")
                fig.add_hline(y=0, line_dash="dash", line_color="rgba(255,255,255,0.3)")
                fig.update_layout(**PLOTLY_LAYOUT, height=chart_h)
                _render_chart(fig)

        def chart_load_ratio():
            st.markdown("**è®­ç»ƒè´Ÿè·æ¯”è¶‹åŠ¿**")
            if "trainingLoadRatio" in df_days.columns:
                ratio_data = df_days[df_days["trainingLoadRatio"] > 0]
                if not ratio_data.empty:
                    fig = go.Figure()
                    fig.add_scatter(x=ratio_data["date_str"], y=ratio_data["trainingLoadRatio"],
                                    mode="lines+markers", line_color="#a78bfa", name="è´Ÿè·æ¯”")
                    fig.add_hline(y=1.0, line_dash="dash", line_color="rgba(255,255,255,0.3)")
                    fig.add_hrect(y0=0.8, y1=1.5, fillcolor="rgba(34,197,94,0.1)", line_width=0, annotation_text="æœ€ä½³åŒºé—´")
                    fig.update_layout(**PLOTLY_LAYOUT, height=chart_h)
                    _render_chart(fig)

        all_charts = [
            chart_training_load, chart_vo2max, chart_rhr, chart_7d_28d,
            chart_weekly_vol, chart_intensity, chart_pace_zone, chart_hr_zone,
            chart_fatigue, chart_load_ratio,
        ]

        for row_start in range(0, len(all_charts), ncols):
            row_charts = all_charts[row_start : row_start + ncols]
            cols = st.columns(ncols)
            for col, fn in zip(cols, row_charts):
                with col:
                    fn()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 3 â€“ Activity List
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab_activities:
    st.subheader(f"æ´»åŠ¨åˆ—è¡¨ ({len(activities_raw)} æ¡è®°å½•)")

    # Filters
    fc1, fc2, fc3 = st.columns([1, 1, 2])
    all_sport_types = sorted({a.get("sportType", 0) for a in activities_raw})
    type_options = ["å…¨éƒ¨"] + [f"{sport_icon(t)} {sport_name(t)}" for t in all_sport_types]
    type_map = {f"{sport_icon(t)} {sport_name(t)}": t for t in all_sport_types}

    with fc1:
        selected_type = st.selectbox("è¿åŠ¨ç±»å‹", type_options)
    with fc2:
        sort_col = st.selectbox("æ’åº", ["æ—¥æœŸ", "è·ç¦»", "æ—¶é—´", "å¿ƒç‡", "è®­ç»ƒè´Ÿè·"])

    filtered = activities_raw
    if selected_type != "å…¨éƒ¨":
        target_type = type_map.get(selected_type)
        if target_type is not None:
            filtered = [a for a in filtered if a.get("sportType") == target_type]

    sort_keys = {
        "æ—¥æœŸ": lambda a: a.get("startTime", 0),
        "è·ç¦»": lambda a: a.get("distance", 0),
        "æ—¶é—´": lambda a: a.get("totalTime", 0),
        "å¿ƒç‡": lambda a: a.get("avgHr", 0),
        "è®­ç»ƒè´Ÿè·": lambda a: a.get("trainingLoad", 0),
    }
    filtered.sort(key=sort_keys.get(sort_col, sort_keys["æ—¥æœŸ"]), reverse=True)

    # Pagination
    page_size = 30
    total_pages = max(1, math.ceil(len(filtered) / page_size))
    with fc3:
        page_num = st.number_input("é¡µç ", 1, total_pages, 1, key="act_page")
    start = (page_num - 1) * page_size
    page_items = filtered[start : start + page_size]

    rows = []
    for a in page_items:
        pace_val = a.get("adjustedPace") or a.get("avgSpeed", 0)
        rows.append({
            "æ—¥æœŸ": fmt_date(a.get("date", 0)),
            "ç±»å‹": sport_icon(a.get("sportType", 0)),
            "åç§°": a.get("name", ""),
            "è·ç¦»": fmt_distance(a.get("distance", 0)),
            "æ—¶é—´": fmt_duration(a.get("totalTime", 0)),
            "é…é€Ÿ": fmt_pace(pace_val) if a.get("sportType", 0) in (100, 102) else "--",
            "å¹³å‡å¿ƒç‡": a.get("avgHr", "--"),
            "è®­ç»ƒè´Ÿè·": a.get("trainingLoad", "--"),
        })
    if rows:
        st.dataframe(
            pd.DataFrame(rows),
            width="stretch",
            hide_index=True,
            height=min(len(rows) * 38 + 40, 900),
        )
    st.caption(f"ç¬¬ {page_num}/{total_pages} é¡µ Â· å…± {len(filtered)} æ¡")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TAB 4 â€“ Training Plan (Concurrent Training)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab_plan:
    PLANS_DIR.mkdir(parents=True, exist_ok=True)
    TODO_FILE = DATA_DIR / "plan_todo_state.json"

    def load_todo_state() -> dict:
        if TODO_FILE.exists():
            with open(TODO_FILE, "r") as f:
                return json.load(f)
        return {}

    def save_todo_state(state: dict):
        with open(TODO_FILE, "w") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)

    if "todo_state" not in st.session_state:
        st.session_state.todo_state = load_todo_state()

    # Auto-complete days that have actual COROS activity data
    act_dates_with_data = set()
    for a in activities_raw:
        d = a.get("date", 0)
        if d:
            act_dates_with_data.add(parse_date(d).isoformat())

    def auto_sync_todo(phases):
        changed = False
        for phase in phases:
            for week in phase["weeks"]:
                for day in week["days"]:
                    dd = day["date"]
                    if dd in act_dates_with_data and not st.session_state.todo_state.get(dd, False):
                        st.session_state.todo_state[dd] = True
                        changed = True
        if changed:
            save_todo_state(st.session_state.todo_state)

    # â”€â”€ Concrete concurrent training plan â”€â”€
    RACE_A = {"name": "ä¹åå±±å—åŒ—ç©¿è¶Š", "date": "2026-03-08", "dist": "40km", "elev": "4000m"}
    RACE_B = {"name": "æ— é”¡é©¬æ‹‰æ¾", "date": "2026-03-22", "dist": "å…¨é©¬", "goal": "Sub-3"}

    PLAN_PHASES = [
        {
            "name": "ä¹åå±±èµ›å‰å‡é‡",
            "tag": "TAPER-A",
            "weeks": [
                {
                    "label": "å‡é‡å‘¨",
                    "dates": ("2026-02-24", "2026-03-02"),
                    "target_km": "20-25km",
                    "target_tl": "150-200",
                    "days": [
                        {"date": "2026-02-24", "wd": "å‘¨ä¸€", "am": "", "noon": "åŠ›é‡ï¼šç¡¬æ‹‰3x3+å§æ¨3x5ï¼ˆå‡é‡40%ï¼‰", "pm": "ä¼‘æ¯", "tl": 15, "type": "strength"},
                        {"date": "2026-02-25", "wd": "å‘¨äºŒ", "am": "", "noon": "", "pm": "è½»æ¾è·‘ 6km Z2ï¼ˆHR<145ï¼‰", "tl": 35, "type": "easy_run"},
                        {"date": "2026-02-26", "wd": "å‘¨ä¸‰", "am": "", "noon": "åŠ›é‡ï¼šæ·±è¹²3x3+è…¹è‚Œï¼ˆå‡é‡40%ï¼‰", "pm": "ä¼‘æ¯/æ‹‰ä¼¸", "tl": 15, "type": "strength"},
                        {"date": "2026-02-27", "wd": "å‘¨å››", "am": "", "noon": "", "pm": "å¡åº¦è·‘ 8kmï¼ˆå«4kmçˆ¬å¡æ¨¡æ‹Ÿï¼‰", "tl": 55, "type": "hill_run"},
                        {"date": "2026-02-28", "wd": "å‘¨äº”", "am": "", "noon": "åŠ›é‡ï¼šè½»å§æ¨2x8+æ‰‹è‡‚", "pm": "ä¼‘æ¯", "tl": 10, "type": "strength"},
                        {"date": "2026-03-01", "wd": "å‘¨å…­", "am": "é•¿è·ç¦» 12kmï¼ˆå«å¡åº¦ï¼ŒZ2-Z3ï¼‰", "noon": "", "pm": "", "tl": 80, "type": "long_run"},
                        {"date": "2026-03-02", "wd": "å‘¨æ—¥", "am": "", "noon": "", "pm": "å®Œå…¨ä¼‘æ¯", "tl": 0, "type": "rest"},
                    ],
                },
                {
                    "label": "èµ›å‰æœ€åä¸€å‘¨",
                    "dates": ("2026-03-03", "2026-03-08"),
                    "target_km": "10-15km",
                    "target_tl": "80-120",
                    "days": [
                        {"date": "2026-03-03", "wd": "å‘¨ä¸€", "am": "", "noon": "åŠ›é‡ï¼šæè½»æ¿€æ´»ï¼ˆæ¯é¡¹1x5ï¼‰", "pm": "ä¼‘æ¯", "tl": 5, "type": "strength"},
                        {"date": "2026-03-04", "wd": "å‘¨äºŒ", "am": "", "noon": "", "pm": "è½»æ¾è·‘ 5km Z1-Z2ï¼ˆHR<140ï¼‰", "tl": 25, "type": "easy_run"},
                        {"date": "2026-03-05", "wd": "å‘¨ä¸‰", "am": "", "noon": "æ‹‰ä¼¸+æ³¡æ²«è½´", "pm": "ä¼‘æ¯", "tl": 0, "type": "recovery"},
                        {"date": "2026-03-06", "wd": "å‘¨å››", "am": "", "noon": "", "pm": "æŠ–è…¿æ…¢è·‘ 3kmï¼ˆçº¯æ¿€æ´»ï¼‰", "tl": 10, "type": "easy_run"},
                        {"date": "2026-03-07", "wd": "å‘¨äº”", "am": "", "noon": "", "pm": "å®Œå…¨ä¼‘æ¯ + è£…å¤‡æ£€æŸ¥", "tl": 0, "type": "rest"},
                        {"date": "2026-03-08", "wd": "å‘¨å…­", "am": "ğŸ”ï¸ ä¹åå±±å—åŒ—ç©¿è¶Š 40km", "noon": "", "pm": "", "tl": 800, "type": "race"},
                    ],
                },
            ],
        },
        {
            "name": "æ¢å¤ + æ— é”¡å¤‡èµ›",
            "tag": "RECOVERY+TAPER-B",
            "weeks": [
                {
                    "label": "æ¢å¤å‘¨",
                    "dates": ("2026-03-09", "2026-03-15"),
                    "target_km": "15-25km",
                    "target_tl": "100-180",
                    "days": [
                        {"date": "2026-03-09", "wd": "å‘¨æ—¥", "am": "", "noon": "", "pm": "å®Œå…¨ä¼‘æ¯ï¼ˆèµ›åç¬¬1å¤©ï¼‰", "tl": 0, "type": "rest"},
                        {"date": "2026-03-10", "wd": "å‘¨ä¸€", "am": "", "noon": "", "pm": "æ­¥è¡Œ30min + æ‹‰ä¼¸20min", "tl": 5, "type": "recovery"},
                        {"date": "2026-03-11", "wd": "å‘¨äºŒ", "am": "", "noon": "", "pm": "æè½»æ¾è·‘30minï¼ˆæµ‹è¯•è…¿éƒ¨ï¼‰", "tl": 20, "type": "easy_run"},
                        {"date": "2026-03-12", "wd": "å‘¨ä¸‰", "am": "", "noon": "åŠ›é‡ï¼šæè½»æ¿€æ´»ï¼ˆä¸Šè‚¢ä¸ºä¸»ï¼‰", "pm": "ä¼‘æ¯", "tl": 10, "type": "strength"},
                        {"date": "2026-03-13", "wd": "å‘¨å››", "am": "", "noon": "", "pm": "è½»æ¾è·‘ 6km Z2", "tl": 35, "type": "easy_run"},
                        {"date": "2026-03-14", "wd": "å‘¨äº”", "am": "", "noon": "åŠ›é‡ï¼šä¸­ç­‰ï¼ˆä¸Šè‚¢ä¸ºä¸»ï¼Œé¿å…æ·±è¹²ï¼‰", "pm": "ä¼‘æ¯", "tl": 15, "type": "strength"},
                        {"date": "2026-03-15", "wd": "å‘¨å…­", "am": "ä¸­è·ç¦» 12kmï¼ˆå«4km@é©¬æ‹‰æ¾é…é€Ÿè¯•è·‘ï¼‰", "noon": "", "pm": "", "tl": 90, "type": "tempo_run"},
                    ],
                },
                {
                    "label": "æ— é”¡èµ›å‰å‡é‡",
                    "dates": ("2026-03-16", "2026-03-22"),
                    "target_km": "15-20km",
                    "target_tl": "80-150",
                    "days": [
                        {"date": "2026-03-16", "wd": "å‘¨ä¸€", "am": "", "noon": "åŠ›é‡ï¼šè½»é‡ç»´æŒ", "pm": "ä¼‘æ¯", "tl": 10, "type": "strength"},
                        {"date": "2026-03-17", "wd": "å‘¨äºŒ", "am": "", "noon": "", "pm": "è´¨é‡è·‘ 8kmï¼šå«4x1km@Té…é€Ÿï¼ˆ3'46\"ï¼‰", "tl": 80, "type": "interval"},
                        {"date": "2026-03-18", "wd": "å‘¨ä¸‰", "am": "", "noon": "æ‹‰ä¼¸+æ³¡æ²«è½´", "pm": "ä¼‘æ¯", "tl": 0, "type": "recovery"},
                        {"date": "2026-03-19", "wd": "å‘¨å››", "am": "", "noon": "", "pm": "è½»æ¾è·‘ 5km Z2", "tl": 25, "type": "easy_run"},
                        {"date": "2026-03-20", "wd": "å‘¨äº”", "am": "", "noon": "", "pm": "å®Œå…¨ä¼‘æ¯", "tl": 0, "type": "rest"},
                        {"date": "2026-03-21", "wd": "å‘¨å…­", "am": "æŠ–è…¿æ…¢è·‘ 3km + èµ›å‰å‡†å¤‡", "noon": "", "pm": "", "tl": 10, "type": "easy_run"},
                        {"date": "2026-03-22", "wd": "å‘¨æ—¥", "am": "ğŸƒ æ— é”¡é©¬æ‹‰æ¾å…¨é©¬ ç›®æ ‡2:55-2:59", "noon": "", "pm": "", "tl": 500, "type": "race"},
                    ],
                },
            ],
        },
        {
            "name": "èµ›åæ¢å¤",
            "tag": "RECOVERY",
            "weeks": [
                {
                    "label": "æ¢å¤å‘¨",
                    "dates": ("2026-03-23", "2026-03-29"),
                    "target_km": "0-15km",
                    "target_tl": "50-100",
                    "days": [
                        {"date": "2026-03-23", "wd": "å‘¨ä¸€", "am": "", "noon": "", "pm": "å®Œå…¨ä¼‘æ¯", "tl": 0, "type": "rest"},
                        {"date": "2026-03-24", "wd": "å‘¨äºŒ", "am": "", "noon": "", "pm": "æ­¥è¡Œ30min + æ‹‰ä¼¸", "tl": 5, "type": "recovery"},
                        {"date": "2026-03-25", "wd": "å‘¨ä¸‰", "am": "", "noon": "", "pm": "æè½»æ¾è·‘20min", "tl": 10, "type": "easy_run"},
                        {"date": "2026-03-26", "wd": "å‘¨å››", "am": "", "noon": "", "pm": "ä¼‘æ¯", "tl": 0, "type": "rest"},
                        {"date": "2026-03-27", "wd": "å‘¨äº”", "am": "", "noon": "åŠ›é‡ï¼šæè½»æ¿€æ´»", "pm": "è½»æ¾è·‘30min", "tl": 25, "type": "easy_run"},
                        {"date": "2026-03-28", "wd": "å‘¨å…­", "am": "è½»æ¾è·‘ 6km Z2", "noon": "", "pm": "", "tl": 35, "type": "easy_run"},
                        {"date": "2026-03-29", "wd": "å‘¨æ—¥", "am": "", "noon": "", "pm": "ä¼‘æ¯/è½»æ¾æ­¥è¡Œ", "tl": 0, "type": "rest"},
                    ],
                },
            ],
        },
    ]

    auto_sync_todo(PLAN_PHASES)

    TYPE_COLORS = {
        "race": "#ef4444", "interval": "#f97316", "tempo_run": "#eab308",
        "hill_run": "#a855f7", "long_run": "#3b82f6", "easy_run": "#22c55e",
        "strength": "#06b6d4", "recovery": "#64748b", "rest": "#374151",
    }
    TYPE_LABELS = {
        "race": "æ¯”èµ›", "interval": "é—´æ­‡", "tempo_run": "èŠ‚å¥è·‘",
        "hill_run": "å¡åº¦è·‘", "long_run": "é•¿è·ç¦»", "easy_run": "è½»æ¾è·‘",
        "strength": "åŠ›é‡", "recovery": "æ¢å¤", "rest": "ä¼‘æ¯",
    }

    # â”€â”€ Header â”€â”€
    st.markdown(
        '<h2 style="margin-bottom:0">æ··åˆè®­ç»ƒè®¡åˆ’ï¼šä¹åå±± + æ— é”¡é©¬æ‹‰æ¾</h2>',
        unsafe_allow_html=True,
    )
    st.markdown(
        f'<p style="color:#94a3b8;margin-top:4px;font-size:0.95rem">'
        f'Concurrent Training Â· 2026-02-24 â€” 2026-03-29 (5 weeks)<br>'
        f'Aèµ› <strong style="color:#ef4444">{RACE_A["date"]}</strong> {RACE_A["name"]} {RACE_A["dist"]}ï¼ˆçˆ¬å‡{RACE_A["elev"]}ï¼‰&nbsp;&nbsp;|&nbsp;&nbsp;'
        f'Bèµ› <strong style="color:#3b82f6">{RACE_B["date"]}</strong> {RACE_B["name"]} ç›®æ ‡{RACE_B["goal"]}</p>',
        unsafe_allow_html=True,
    )

    # â”€â”€ Race countdown â”€â”€
    today = date.today()
    days_to_a = (date.fromisoformat(RACE_A["date"]) - today).days
    days_to_b = (date.fromisoformat(RACE_B["date"]) - today).days

    rc1, rc2, rc3, rc4 = st.columns(4)
    a_label = "èµ›å" if days_to_a < 0 else f"{days_to_a} å¤©å"
    b_label = "èµ›å" if days_to_b < 0 else f"{days_to_b} å¤©å"
    rc1.metric("ğŸ”ï¸ ä¹åå±±", a_label, f"{RACE_A['dist']} Â· {RACE_A['elev']}")
    rc2.metric("ğŸƒ æ— é”¡é©¬æ‹‰æ¾", b_label, f"ç›®æ ‡ {RACE_B['goal']}")

    all_plan_days = [d for p in PLAN_PHASES for w in p["weeks"] for d in w["days"]]
    total_done = sum(1 for d in all_plan_days if st.session_state.todo_state.get(d["date"], False))
    rc3.metric("å®Œæˆè¿›åº¦", f"{total_done} / {len(all_plan_days)}", f"{total_done/max(len(all_plan_days),1)*100:.0f}%")

    past_days = [d for d in all_plan_days if d["date"] <= today.isoformat()]
    past_done = sum(1 for d in past_days if st.session_state.todo_state.get(d["date"], False))
    behind = len(past_days) - past_done
    rc4.metric("åº”å®Œæˆ", f"{past_done} / {len(past_days)}", "å…¨éƒ¨å®Œæˆ" if behind == 0 and past_days else f"å·® {behind} å¤©" if past_days else "æœªå¼€å§‹")

    # Legend
    legend_html = '<div style="display:flex;flex-wrap:wrap;gap:12px;margin:8px 0 16px">'
    for tp, color in TYPE_COLORS.items():
        legend_html += f'<span style="display:flex;align-items:center;gap:4px"><span style="width:12px;height:12px;border-radius:3px;background:{color};display:inline-block"></span>{TYPE_LABELS[tp]}</span>'
    legend_html += '</div>'
    st.markdown(legend_html, unsafe_allow_html=True)

    # â”€â”€ Render phases and weeks â”€â”€
    today_str = today.isoformat()

    for phase in PLAN_PHASES:
        st.markdown(f"#### {phase['tag']}ï¼š{phase['name']}")

        for week in phase["weeks"]:
            w_start = date.fromisoformat(week["dates"][0])
            w_end = date.fromisoformat(week["dates"][1])
            is_current = w_start <= today <= w_end

            border = "border:2px solid #3b82f6;" if is_current else "border:1px solid #2d3748;"
            st.markdown(
                f'<div style="background:#1a1f2e;{border}border-radius:10px;padding:14px;margin-bottom:12px">'
                f'<div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:10px">'
                f'<div><strong style="font-size:1.05em">{week["label"]}</strong>'
                f' <span style="color:#94a3b8;font-size:0.85em">{week["dates"][0]} ~ {week["dates"][1]}</span></div>'
                f'<div style="color:#94a3b8;font-size:0.85em">ç›®æ ‡: {week["target_km"]} Â· TL {week["target_tl"]}</div>'
                f'</div></div>',
                unsafe_allow_html=True,
            )

            # Build activity lookup by ISO date
            act_by_date = {}
            for a in activities_raw:
                d = a.get("date", 0)
                if d:
                    ds = parse_date(d).isoformat()
                    act_by_date.setdefault(ds, []).append(a)

            for day in week["days"]:
                d_date = date.fromisoformat(day["date"])
                is_today = day["date"] == today_str
                is_race = day["type"] == "race"

                color = TYPE_COLORS.get(day["type"], "#374151")
                todo_key = day["date"]

                # Planned sessions
                sessions = []
                if day["noon"]:
                    sessions.append(f"ğŸ”© ä¸­åˆ: {day['noon']}")
                if day["am"]:
                    sessions.append(f"ğŸŒ… ä¸Šåˆ: {day['am']}")
                if day["pm"]:
                    sessions.append(f"ğŸŒ™ ä¸‹åˆ/æ™š: {day['pm']}")
                session_text = " ï½œ ".join(sessions) if sessions else "ä¼‘æ¯"

                # Actual COROS data for this day
                day_acts = act_by_date.get(day["date"], [])
                actual_parts = []
                actual_tl = 0
                for a in day_acts:
                    name = a.get("name", "")
                    dist = a.get("distance", 0)
                    dur = a.get("totalTime", 0)
                    tl = a.get("trainingLoad", 0)
                    actual_tl += tl
                    desc = name
                    if dist > 0:
                        desc += f" {fmt_distance(dist)}"
                    if dur > 0:
                        desc += f" {fmt_duration(dur)}"
                    if tl > 0:
                        desc += f" TL{tl}"
                    actual_parts.append(desc)
                actual_text = " + ".join(actual_parts) if actual_parts else ""

                col_check, col_info = st.columns([0.06, 0.94])
                with col_check:
                    checked = st.checkbox(
                        "done",
                        value=st.session_state.todo_state.get(todo_key, False),
                        key=f"todo_{todo_key}",
                        label_visibility="collapsed",
                    )
                    if checked != st.session_state.todo_state.get(todo_key, False):
                        st.session_state.todo_state[todo_key] = checked
                        save_todo_state(st.session_state.todo_state)

                with col_info:
                    today_marker = ' style="border-left:3px solid #fff;padding-left:8px"' if is_today else ""
                    done_class = "todo-done" if checked else ""
                    race_badge = f' <span style="background:{color};color:#fff;padding:2px 8px;border-radius:4px;font-weight:bold;font-size:0.8em">{TYPE_LABELS[day["type"]]}</span>' if is_race else f' <span style="color:{color};font-size:0.8em">â— {TYPE_LABELS[day["type"]]}</span>'
                    tl_badge = f' <span style="color:#94a3b8;font-size:0.8em">TLâ‰ˆ{day["tl"]}</span>' if day["tl"] > 0 else ""

                    actual_line = ""
                    if actual_text:
                        actual_line = f'<br><span style="color:#22c55e;font-size:0.85em">âœ… å®é™…: {actual_text}</span>'

                    st.markdown(
                        f'<div{today_marker}>'
                        f'<span class="{done_class}">'
                        f'<strong>{day["wd"]} {day["date"][5:]}</strong>{race_badge}{tl_badge}'
                        f'<br><span style="color:#d1d5db;font-size:0.9em">{session_text}</span>'
                        f'{actual_line}'
                        f'</span></div>',
                        unsafe_allow_html=True,
                    )

    # â”€â”€ Export â”€â”€
    st.divider()
    st.subheader("å¯¼å‡ºè®­ç»ƒè®¡åˆ’")

    def build_plan_markdown() -> str:
        lines = [
            "# æ··åˆè®­ç»ƒè®¡åˆ’ï¼šä¹åå±± + æ— é”¡é©¬æ‹‰æ¾",
            f"",
            f"Aèµ›ï¼š{RACE_A['date']} {RACE_A['name']} {RACE_A['dist']}ï¼ˆçˆ¬å‡{RACE_A['elev']}ï¼‰",
            f"Bèµ›ï¼š{RACE_B['date']} {RACE_B['name']} ç›®æ ‡{RACE_B['goal']}",
            f"",
            "---",
            "",
        ]
        for phase in PLAN_PHASES:
            lines.append(f"## {phase['tag']}ï¼š{phase['name']}")
            lines.append("")
            for week in phase["weeks"]:
                lines.append(f"### {week['label']}ï¼ˆ{week['dates'][0]} ~ {week['dates'][1]}ï¼‰")
                lines.append(f"ç›®æ ‡è·‘é‡: {week['target_km']} Â· ç›®æ ‡è´Ÿè·: TL {week['target_tl']}")
                lines.append("")
                lines.append("| æ—¥æœŸ | æ˜ŸæœŸ | ä¸­åˆè®­ç»ƒ | è·‘æ­¥è®­ç»ƒ | é¢„ä¼°TL |")
                lines.append("|------|------|----------|----------|--------|")
                for d in week["days"]:
                    noon = d["noon"] or "â€”"
                    run = d["am"] or d["pm"] or "ä¼‘æ¯"
                    lines.append(f"| {d['date']} | {d['wd']} | {noon} | {run} | {d['tl']} |")
                lines.append("")
        lines.append("---")
        lines.append("")
        lines.append("## COROS æ‰‹åŠ¨å½•å…¥æŒ‡å—")
        lines.append("")
        lines.append("1. æ‰“å¼€ t.coros.com â†’ æ—¥ç¨‹ tab")
        lines.append("2. ç‚¹å‡»å¯¹åº”æ—¥æœŸ â†’ æ·»åŠ è®­ç»ƒè®¡åˆ’")
        lines.append("3. æŒ‰ä¸Šè¡¨å†…å®¹è®¾ç½®è®­ç»ƒç±»å‹ã€æ—¶é•¿ã€å¿ƒç‡åŒºé—´")
        lines.append("4. å¯¹äºè·‘æ­¥è®­ç»ƒï¼šè®¾ç½®ç›®æ ‡å¿ƒç‡æˆ–é…é€Ÿ")
        lines.append("5. å¯¹äºåŠ›é‡è®­ç»ƒï¼šè®¾ç½®æ—¶é•¿å’Œè®­ç»ƒç±»å‹")
        return "\n".join(lines)

    plan_md = build_plan_markdown()

    ec1, ec2 = st.columns(2)
    with ec1:
        st.download_button(
            "ğŸ“¥ ä¸‹è½½è®­ç»ƒè®¡åˆ’ï¼ˆMarkdownï¼‰",
            plan_md,
            file_name="concurrent_training_plan_2026.md",
            mime="text/markdown",
        )
    with ec2:
        plan_json_export = json.dumps(
            {"races": [RACE_A, RACE_B], "phases": PLAN_PHASES},
            ensure_ascii=False, indent=2, default=str,
        )
        st.download_button(
            "ğŸ“¥ ä¸‹è½½è®­ç»ƒè®¡åˆ’ï¼ˆJSONï¼‰",
            plan_json_export,
            file_name="concurrent_training_plan_2026.json",
            mime="application/json",
        )

    st.divider()
    st.subheader("å¯¼å…¥è®¡åˆ’åˆ° COROS")
    st.caption("è¯»å– data/save_plan.json ä¸­çš„ä¿®æ”¹è®¡åˆ’æ•°æ®ï¼Œé€šè¿‡æ–°å¢æ¥å£åˆ›å»ºæ–°è®¡åˆ’ï¼ˆæ¯æ¬¡åˆ›å»ºç‹¬ç«‹å‰¯æœ¬ï¼Œåç§°å¸¦æ—¶é—´æˆ³ï¼‰")

    if st.button("ğŸš€ å¯¼å…¥è®¡åˆ’åˆ° COROS", type="primary"):
        with st.spinner("æ­£åœ¨åˆ›å»ºæ–°è®¡åˆ’..."):
            success, message = import_plan_to_coros()
        if success:
            st.toast(message, icon="âœ…")
            st.success(message)
            st.balloons()
        elif message == "__TOKEN_INVALID__":
            st.toast("Token å·²å¤±æ•ˆï¼Œè¯·æ›´æ–°å‡­æ®", icon="ğŸ”‘")
            show_token_invalid_guide(key_suffix="import")
        else:
            st.toast(message, icon="âŒ")
            st.error(message)
